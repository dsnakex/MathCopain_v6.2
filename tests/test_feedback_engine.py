"""
Tests pour FeedbackEngine - Phase 6.1.3
Couverture: 85%+

Tests pour:
- TransformativeFeedbackResult
- RemediationRecommender
- TransformativeFeedback (FeedbackGenerator)
"""

import pytest
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any

from core.pedagogy.feedback_engine import (
    TransformativeFeedbackResult,
    RemediationRecommender,
    TransformativeFeedback,
    FeedbackGenerator
)
from core.pedagogy.error_analyzer import ErrorAnalyzer, ErrorAnalysisResult


# ============================================================================
# FIXTURES
# ============================================================================

@pytest.fixture
def feedback_engine():
    """Instance de TransformativeFeedback"""
    return TransformativeFeedback()


@pytest.fixture
def remediation_recommender():
    """Instance de RemediationRecommender"""
    return RemediationRecommender()


@pytest.fixture
def error_analyzer():
    """Instance de ErrorAnalyzer"""
    return ErrorAnalyzer()


@pytest.fixture
def sample_addition_exercise():
    """Exercice d'addition simple"""
    return {
        "type": "addition",
        "operation": "25 + 17",
        "difficulty": "CE2",
        "operand1": 25,
        "operand2": 17,
        "expected_answer": 42
    }


@pytest.fixture
def sample_subtraction_exercise():
    """Exercice de soustraction avec emprunt"""
    return {
        "type": "subtraction",
        "operation": "52 - 27",
        "difficulty": "CE2",
        "operand1": 52,
        "operand2": 27,
        "expected_answer": 25
    }


@pytest.fixture
def sample_multiplication_exercise():
    """Exercice de multiplication"""
    return {
        "type": "multiplication",
        "operation": "7 √ó 8",
        "difficulty": "CE2",
        "operand1": 7,
        "operand2": 8,
        "expected_answer": 56
    }


@pytest.fixture
def sample_division_exercise():
    """Exercice de division"""
    return {
        "type": "division",
        "operation": "48 √∑ 6",
        "difficulty": "CM1",
        "operand1": 48,
        "operand2": 6,
        "expected_answer": 8
    }


@pytest.fixture
def sample_user_history_good():
    """Historique utilisateur avec bon taux de r√©ussite"""
    return {
        "user_id": "student_123",
        "success_rate": 0.85,
        "exercises_completed": 50,
        "current_streak": 5
    }


@pytest.fixture
def sample_user_history_struggling():
    """Historique utilisateur en difficult√©"""
    return {
        "user_id": "student_456",
        "success_rate": 0.45,
        "exercises_completed": 30,
        "current_streak": 0
    }


@pytest.fixture
def sample_error_analysis_severe():
    """Analyse d'erreur s√©v√®re"""
    return ErrorAnalysisResult(
        error_type="Conceptual",
        misconception="Confond addition et multiplication",
        severity=4,
        confidence=0.85,
        examples=["7+8=56 au lieu de 15"],
        prerequisites_gaps=["concept_addition", "concept_multiplication"],
        remediation_strategy="Reprendre les concepts fondamentaux",
        common_ages=["7-8 ans"],
        error_id="MULT_CONC_002",
        feedback_templates=[
            "La multiplication, c'est une addition r√©p√©t√©e: {a} √ó {b} = {a} + {a} + ... ({b} fois).",
            "C'est diff√©rent de l'addition! {a} √ó {b} = {result}, mais {a} + {b} = {sum}."
        ],
        remediation_path="multiplication_concepts_fundamentals"
    )


@pytest.fixture
def sample_error_analysis_moderate():
    """Analyse d'erreur mod√©r√©e"""
    return ErrorAnalysisResult(
        error_type="Procedural",
        misconception="Oublie la retenue en addition",
        severity=3,
        confidence=0.75,
        examples=["25+17=32 au lieu de 42"],
        prerequisites_gaps=["addition_with_carry"],
        remediation_strategy="Pratiquer additions avec retenue",
        common_ages=["7-9 ans"],
        error_id="ADD_PROC_001",
        feedback_templates=[
            "Attention √† la retenue! Quand {a} + {b} = {sum}, et que {sum} ‚â• 10, on doit reporter {carry} dizaine(s).",
            "Tu as oubli√© de reporter la retenue. Regarde: {a} + {b} = {correct}, pas {wrong}."
        ],
        remediation_path="addition_with_carry_basics"
    )


@pytest.fixture
def sample_error_analysis_light():
    """Analyse d'erreur l√©g√®re (calcul mental)"""
    return ErrorAnalysisResult(
        error_type="Calculation",
        misconception="Erreur de calcul mental",
        severity=1,
        confidence=0.60,
        examples=["7+8=14 au lieu de 15"],
        prerequisites_gaps=[],
        remediation_strategy="Pratiquer calcul mental",
        common_ages=["6-10 ans"],
        error_id="CALC_001",
        feedback_templates=[
            "V√©rifie ton calcul: {a} {op} {b} = {correct}, pas {wrong}.",
            "Prends ton temps pour bien calculer!"
        ],
        remediation_path="calculation_skills_practice"
    )


# ============================================================================
# TESTS - TransformativeFeedbackResult
# ============================================================================

class TestTransformativeFeedbackResult:
    """Tests pour la dataclass TransformativeFeedbackResult"""

    def test_creation_minimal(self):
        """Cr√©ation avec champs minimaux"""
        result = TransformativeFeedbackResult(
            immediate="‚úÖ Exact!",
            explanation="Tu as bien r√©solu cette addition!"
        )
        assert result.immediate == "‚úÖ Exact!"
        assert result.explanation == "Tu as bien r√©solu cette addition!"
        assert result.strategy is None
        assert result.remediation is None
        assert result.encouragement == ""
        assert result.next_action == "Continuer"
        assert result.is_correct is False
        assert result.confidence == 0.0

    def test_creation_complete(self):
        """Cr√©ation avec tous les champs"""
        result = TransformativeFeedbackResult(
            immediate="‚ùå Pas exactement",
            explanation="Tu as oubli√© la retenue",
            strategy="Essaie en d√©composant",
            remediation={"path": "addition_basics", "count": 3},
            encouragement="üí™ Continue!",
            next_action="Refaire exercice",
            is_correct=False,
            confidence=0.85,
            timestamp="2025-11-15T10:30:00"
        )
        assert result.immediate == "‚ùå Pas exactement"
        assert result.explanation == "Tu as oubli√© la retenue"
        assert result.strategy == "Essaie en d√©composant"
        assert result.remediation["path"] == "addition_basics"
        assert result.encouragement == "üí™ Continue!"
        assert result.next_action == "Refaire exercice"
        assert result.is_correct is False
        assert result.confidence == 0.85

    def test_to_dict(self):
        """Conversion en dictionnaire"""
        result = TransformativeFeedbackResult(
            immediate="‚úÖ Parfait!",
            explanation="Excellente r√©ponse!",
            is_correct=True,
            confidence=1.0
        )
        d = result.to_dict()
        assert isinstance(d, dict)
        assert d["immediate"] == "‚úÖ Parfait!"
        assert d["explanation"] == "Excellente r√©ponse!"
        assert d["is_correct"] is True
        assert d["confidence"] == 1.0
        assert "strategy" in d
        assert "remediation" in d

    def test_to_dict_with_all_fields(self):
        """Conversion en dict avec tous les champs remplis"""
        result = TransformativeFeedbackResult(
            immediate="‚ùå V√©rifions",
            explanation="Erreur de retenue",
            strategy="D√©compose en unit√©s/dizaines",
            remediation={"path": "add_carry", "difficulty": "CE1"},
            encouragement="üåü Tu vas y arriver!",
            next_action="Voir explication",
            is_correct=False,
            confidence=0.72,
            timestamp="2025-11-15T14:20:00"
        )
        d = result.to_dict()
        assert d["strategy"] == "D√©compose en unit√©s/dizaines"
        assert d["remediation"]["path"] == "add_carry"
        assert d["encouragement"] == "üåü Tu vas y arriver!"
        assert d["next_action"] == "Voir explication"


# ============================================================================
# TESTS - RemediationRecommender
# ============================================================================

class TestRemediationRecommender:
    """Tests pour RemediationRecommender"""

    def test_initialization(self, remediation_recommender):
        """Initialisation correcte"""
        assert remediation_recommender is not None
        assert hasattr(remediation_recommender, 'difficulty_levels')
        assert len(remediation_recommender.difficulty_levels) == 5

    def test_recommend_severe_error(
        self,
        remediation_recommender,
        sample_error_analysis_severe
    ):
        """Recommandation pour erreur s√©v√®re (severity=4)"""
        rec = remediation_recommender.recommend_exercise(
            sample_error_analysis_severe,
            current_difficulty="CE2"
        )
        assert rec["exercise_path"] == "multiplication_concepts_fundamentals"
        assert rec["difficulty"] == "CE1"  # -2 niveaux
        assert rec["practice_count"] == 5
        assert rec["hints_enabled"] is True
        assert len(rec["focus_prerequisites"]) <= 3

    def test_recommend_moderate_error(
        self,
        remediation_recommender,
        sample_error_analysis_moderate
    ):
        """Recommandation pour erreur mod√©r√©e (severity=3)"""
        rec = remediation_recommender.recommend_exercise(
            sample_error_analysis_moderate,
            current_difficulty="CE2"
        )
        assert rec["exercise_path"] == "addition_with_carry_basics"
        assert rec["difficulty"] == "CE1"  # -1 niveau: CE2 -> CE1
        assert rec["practice_count"] == 3
        assert rec["hints_enabled"] is True

    def test_recommend_light_error(
        self,
        remediation_recommender,
        sample_error_analysis_light
    ):
        """Recommandation pour erreur l√©g√®re (severity=1)"""
        rec = remediation_recommender.recommend_exercise(
            sample_error_analysis_light,
            current_difficulty="CE2"
        )
        assert rec["exercise_path"] == "calculation_skills_practice"
        assert rec["difficulty"] == "CE2"  # M√™me niveau
        assert rec["practice_count"] == 2
        assert rec["hints_enabled"] is False

    def test_adjust_difficulty_down(self, remediation_recommender):
        """Ajustement de difficult√© vers le bas"""
        result = remediation_recommender._adjust_difficulty("CM2", -2)
        assert result == "CE2"  # CM2 (idx 3) -2 = CE2 (idx 1)

        result = remediation_recommender._adjust_difficulty("CE2", -1)
        assert result == "CE1"  # CE2 (idx 1) -1 = CE1 (idx 0)

    def test_adjust_difficulty_up(self, remediation_recommender):
        """Ajustement de difficult√© vers le haut"""
        result = remediation_recommender._adjust_difficulty("CE1", 2)
        assert result == "CM1"

    def test_adjust_difficulty_bounds(self, remediation_recommender):
        """Limites d'ajustement de difficult√©"""
        # Ne peut pas descendre en dessous de CE1
        result = remediation_recommender._adjust_difficulty("CE1", -5)
        assert result == "CE1"

        # Ne peut pas monter au-dessus de CM2
        result = remediation_recommender._adjust_difficulty("CM2", 5)
        assert result == "CM2"

    def test_adjust_difficulty_invalid_level(self, remediation_recommender):
        """Niveau invalide retourne le niveau original"""
        result = remediation_recommender._adjust_difficulty("CP", -1)
        assert result == "CP"

    def test_get_exercise_type_conceptual(self, remediation_recommender):
        """Type d'exercice pour erreur conceptuelle"""
        ex_type = remediation_recommender._get_exercise_type("Conceptual")
        assert ex_type == "guided_discovery"

    def test_get_exercise_type_procedural(self, remediation_recommender):
        """Type d'exercice pour erreur proc√©durale"""
        ex_type = remediation_recommender._get_exercise_type("Procedural")
        assert ex_type == "step_by_step_practice"

    def test_get_exercise_type_calculation(self, remediation_recommender):
        """Type d'exercice pour erreur de calcul"""
        ex_type = remediation_recommender._get_exercise_type("Calculation")
        assert ex_type == "drill_practice"

    def test_get_exercise_type_unknown(self, remediation_recommender):
        """Type d'exercice pour erreur inconnue"""
        ex_type = remediation_recommender._get_exercise_type("Unknown")
        assert ex_type == "mixed_practice"

    def test_estimated_time(self, remediation_recommender, sample_error_analysis_moderate):
        """Temps estim√© bas√© sur practice_count"""
        rec = remediation_recommender.recommend_exercise(
            sample_error_analysis_moderate,
            "CE2"
        )
        # 3 exercices √ó 3 minutes = 9 minutes
        assert rec["estimated_time_minutes"] == 9


# ============================================================================
# TESTS - TransformativeFeedback - V√©rification de r√©ponse
# ============================================================================

class TestTransformativeFeedbackAnswerChecking:
    """Tests pour la v√©rification de r√©ponse"""

    def test_check_answer_correct_integer(self, feedback_engine):
        """R√©ponse correcte - entier"""
        assert feedback_engine._check_answer(42, 42) is True
        assert feedback_engine._check_answer("42", 42) is True
        assert feedback_engine._check_answer(42, "42") is True

    def test_check_answer_correct_float(self, feedback_engine):
        """R√©ponse correcte - d√©cimal"""
        assert feedback_engine._check_answer(3.14, 3.14) is True
        assert feedback_engine._check_answer("3.14", 3.14) is True
        assert feedback_engine._check_answer(3.14, "3.14") is True

    def test_check_answer_correct_with_tolerance(self, feedback_engine):
        """R√©ponse correcte avec tol√©rance d√©cimale"""
        assert feedback_engine._check_answer(3.14159, 3.14160) is True
        assert feedback_engine._check_answer(10.0001, 10.0002) is True

    def test_check_answer_wrong(self, feedback_engine):
        """R√©ponse incorrecte"""
        assert feedback_engine._check_answer(42, 43) is False
        assert feedback_engine._check_answer("wrong", 42) is False
        assert feedback_engine._check_answer(10, 20) is False

    def test_check_answer_case_insensitive(self, feedback_engine):
        """Comparaison insensible √† la casse"""
        assert feedback_engine._check_answer("ABC", "abc") is True
        assert feedback_engine._check_answer("TrUe", "true") is True

    def test_parse_number_integer(self, feedback_engine):
        """Parse d'entier"""
        assert feedback_engine._parse_number(42) == 42.0
        assert feedback_engine._parse_number("42") == 42.0

    def test_parse_number_float(self, feedback_engine):
        """Parse de d√©cimal"""
        assert feedback_engine._parse_number(3.14) == 3.14
        assert feedback_engine._parse_number("3.14") == 3.14

    def test_parse_number_comma(self, feedback_engine):
        """Parse avec virgule fran√ßaise"""
        result = feedback_engine._parse_number("3,14")
        assert abs(result - 3.14) < 0.001

    def test_parse_number_fraction(self, feedback_engine):
        """Parse de fraction"""
        result = feedback_engine._parse_number("1/2")
        assert abs(result - 0.5) < 0.001

        result = feedback_engine._parse_number("3/4")
        assert abs(result - 0.75) < 0.001

    def test_parse_number_invalid(self, feedback_engine):
        """Parse invalide retourne None"""
        assert feedback_engine._parse_number("abc") is None
        assert feedback_engine._parse_number("1/0") is None
        assert feedback_engine._parse_number("") is None


# ============================================================================
# TESTS - TransformativeFeedback - Feedback de succ√®s
# ============================================================================

class TestTransformativeFeedbackSuccess:
    """Tests pour le feedback de succ√®s"""

    def test_process_correct_answer(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Traitement d'une r√©ponse correcte"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=42,
            expected=42,
            user_id="student_123"
        )

        assert result.is_correct is True
        assert result.confidence == 1.0
        assert result.immediate.startswith("‚úÖ")
        assert len(result.explanation) > 0
        assert result.remediation is None
        assert result.next_action in ["Continuer", "Niveau suivant"]

    def test_success_immediate_message(
        self,
        feedback_engine,
        sample_multiplication_exercise
    ):
        """Message imm√©diat pour succ√®s"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_multiplication_exercise,
            response=56,
            expected=56,
            user_id="student_456"
        )

        # Doit contenir un checkmark
        assert "‚úÖ" in result.immediate
        # Doit √™tre court (‚â§5 mots typiquement)
        assert len(result.immediate.split()) <= 6

    def test_success_explanation_contains_operation(
        self,
        feedback_engine,
        sample_subtraction_exercise
    ):
        """Explication mentionne l'op√©ration"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_subtraction_exercise,
            response=25,
            expected=25,
            user_id="student_789"
        )

        # L'explication devrait √™tre pr√©sente et contenir des informations pertinentes
        assert len(result.explanation) > 0
        # L'op√©ration elle-m√™me ou des termes li√©s devraient √™tre pr√©sents
        explanation_lower = result.explanation.lower()
        assert any(word in explanation_lower for word in [
            "52", "27", "soustraction", "subtraction", "exercice", "r√©sol",
            "r√©ponse", "correct", "bien", "ma√Ætrise"
        ])

    def test_success_with_fast_time(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Succ√®s rapide (< 10 secondes)"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=42,
            expected=42,
            user_id="student_123",
            time_taken_seconds=5
        )

        # Devrait mentionner la rapidit√©
        explanation_lower = result.explanation.lower()
        assert "seconde" in explanation_lower or "rapide" in explanation_lower

    def test_success_with_slow_time(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Succ√®s lent (> 60 secondes)"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=42,
            expected=42,
            user_id="student_123",
            time_taken_seconds=75
        )

        # Devrait encourager la r√©flexion
        explanation_lower = result.explanation.lower()
        assert "temps" in explanation_lower or "r√©fl√©chir" in explanation_lower

    def test_success_encouragement_high_success_rate(
        self,
        feedback_engine,
        sample_addition_exercise,
        sample_user_history_good
    ):
        """Encouragement adapt√© au bon √©l√®ve"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=42,
            expected=42,
            user_id="student_123",
            user_history=sample_user_history_good
        )

        # Devrait √™tre positif et encourageant
        assert len(result.encouragement) > 0
        encouragement_lower = result.encouragement.lower()
        assert any(word in encouragement_lower for word in [
            "excellent", "bravo", "continue", "lanc√©e", "progress"
        ])

    def test_success_encouragement_low_success_rate(
        self,
        feedback_engine,
        sample_addition_exercise,
        sample_user_history_struggling
    ):
        """Encouragement adapt√© √† l'√©l√®ve en difficult√©"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=42,
            expected=42,
            user_id="student_456",
            user_history=sample_user_history_struggling
        )

        # Devrait encourager les efforts
        assert len(result.encouragement) > 0
        encouragement_lower = result.encouragement.lower()
        assert any(word in encouragement_lower for word in [
            "bravo", "effort", "paie", "continue"
        ])

    def test_success_next_action_high_performer(
        self,
        feedback_engine,
        sample_addition_exercise,
        sample_user_history_good
    ):
        """Action suivante pour bon √©l√®ve"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=42,
            expected=42,
            user_id="student_123",
            user_history=sample_user_history_good
        )

        # Devrait proposer niveau suivant
        assert result.next_action == "Niveau suivant"

    def test_success_next_action_normal(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Action suivante pour √©l√®ve normal"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=42,
            expected=42,
            user_id="student_789",
            user_history={"success_rate": 0.65}
        )

        # Devrait continuer au m√™me niveau
        assert result.next_action == "Continuer"

    def test_success_strategy_present(
        self,
        feedback_engine,
        sample_multiplication_exercise
    ):
        """Strat√©gie/insight pr√©sent dans succ√®s"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_multiplication_exercise,
            response=56,
            expected=56,
            user_id="student_123"
        )

        # Strategy devrait √™tre pr√©sent
        assert result.strategy is not None
        assert len(result.strategy) > 0


# ============================================================================
# TESTS - TransformativeFeedback - Feedback d'√©chec
# ============================================================================

class TestTransformativeFeedbackFailure:
    """Tests pour le feedback d'√©chec/erreur"""

    def test_process_wrong_answer(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Traitement d'une r√©ponse incorrecte"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=32,  # Erreur: oubli de retenue
            expected=42,
            user_id="student_123"
        )

        assert result.is_correct is False
        assert 0.0 < result.confidence <= 1.0
        assert result.immediate.startswith("‚ùå")
        assert len(result.explanation) > 0
        assert result.strategy is not None
        assert result.remediation is not None
        assert result.next_action != ""

    def test_failure_immediate_severity_light(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Message imm√©diat pour erreur l√©g√®re"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=41,  # Proche de 42
            expected=42,
            user_id="student_123"
        )

        # Devrait √™tre encourageant "presque"
        immediate_lower = result.immediate.lower()
        assert "‚ùå" in result.immediate

    def test_failure_explanation_contains_error(
        self,
        feedback_engine,
        sample_multiplication_exercise
    ):
        """Explication contient l'erreur et la correction"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_multiplication_exercise,
            response=49,
            expected=56,
            user_id="student_456"
        )

        # Devrait mentionner r√©ponse incorrecte et correcte
        explanation_lower = result.explanation.lower()
        assert "49" in result.explanation or "incorrect" in explanation_lower
        assert "56" in result.explanation or "bonne" in explanation_lower

    def test_failure_strategy_appropriate_for_operation(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Strat√©gie appropri√©e pour addition"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=32,
            expected=42,
            user_id="student_123"
        )

        # Strat√©gie pour addition
        strategy_lower = result.strategy.lower()
        assert any(word in strategy_lower for word in [
            "d√©compos", "dizaine", "unit√©", "doigt", "jeton", "arrond"
        ])

    def test_failure_strategy_subtraction(
        self,
        feedback_engine,
        sample_subtraction_exercise
    ):
        """Strat√©gie pour soustraction"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_subtraction_exercise,
            response=35,
            expected=25,
            user_id="student_123"
        )

        strategy_lower = result.strategy.lower()
        assert any(word in strategy_lower for word in [
            "droite", "num√©rique", "diff√©rence", "ajouter", "d√©compos"
        ])

    def test_failure_strategy_multiplication(
        self,
        feedback_engine,
        sample_multiplication_exercise
    ):
        """Strat√©gie pour multiplication"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_multiplication_exercise,
            response=49,
            expected=56,
            user_id="student_123"
        )

        strategy_lower = result.strategy.lower()
        assert any(word in strategy_lower for word in [
            "groupe", "r√©p√®te", "table", "multipli", "fois", "d√©compos"
        ])

    def test_failure_strategy_division(
        self,
        feedback_engine,
        sample_division_exercise
    ):
        """Strat√©gie pour division"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_division_exercise,
            response=6,
            expected=8,
            user_id="student_123"
        )

        strategy_lower = result.strategy.lower()
        assert any(word in strategy_lower for word in [
            "partage", "table", "diviseur", "soustra", "r√©p√©t", "combien"
        ])

    def test_failure_remediation_structure(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Structure de rem√©diation correcte"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=32,
            expected=42,
            user_id="student_123"
        )

        rem = result.remediation
        assert rem is not None
        assert "exercise_path" in rem
        assert "difficulty" in rem
        assert "practice_count" in rem
        assert "estimated_time_minutes" in rem
        assert "exercise_type" in rem

    def test_failure_encouragement_severe(
        self,
        feedback_engine,
        sample_multiplication_exercise
    ):
        """Encouragement pour erreur s√©v√®re"""
        # Simuler erreur s√©v√®re: 7+8=56 (confond addition et multiplication)
        result = feedback_engine.process_exercise_response(
            exercise={
                "type": "addition",
                "operation": "7 + 8",
                "difficulty": "CE1",
                "operand1": 7,
                "operand2": 8,
                "expected_answer": 15
            },
            response=56,
            expected=15,
            user_id="student_123"
        )

        # Devrait √™tre encourageant et positif
        encouragement_lower = result.encouragement.lower()
        assert len(result.encouragement) > 0
        # Devrait contenir des mots encourageants
        assert any(word in encouragement_lower for word in [
            "important", "pratique", "normal", "continue", "ensemble",
            "pas", "souci", "erreur", "apprend", "vas", "arriver", "inqui√®te"
        ])

    def test_failure_next_action_severe(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Action suivante pour erreur s√©v√®re"""
        # Forcer une erreur s√©v√®re via l'analyzer
        result = feedback_engine.process_exercise_response(
            exercise={
                "type": "addition",
                "operation": "7 + 8",
                "difficulty": "CE1",
                "operand1": 7,
                "operand2": 8,
                "expected_answer": 15
            },
            response=56,  # Tr√®s incorrect
            expected=15,
            user_id="student_123"
        )

        # Devrait sugg√©rer explication ou exercice similaire
        assert result.next_action in [
            "Voir explication d√©taill√©e",
            "Refaire exercice similaire",
            "R√©essayer"
        ]

    def test_failure_next_action_moderate(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Action suivante pour erreur mod√©r√©e"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=32,  # Oubli retenue
            expected=42,
            user_id="student_123"
        )

        # Devrait sugg√©rer refaire
        assert result.next_action in [
            "Refaire exercice similaire",
            "R√©essayer",
            "Voir explication d√©taill√©e"
        ]

    def test_failure_next_action_light(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Action suivante pour erreur l√©g√®re"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=41,  # Tr√®s proche
            expected=42,
            user_id="student_123"
        )

        # Devrait sugg√©rer r√©essayer
        assert result.next_action in ["R√©essayer", "Refaire exercice similaire"]


# ============================================================================
# TESTS - TransformativeFeedback - Int√©gration avec ErrorAnalyzer
# ============================================================================

class TestTransformativeFeedbackIntegration:
    """Tests d'int√©gration avec ErrorAnalyzer"""

    def test_integration_analyzer_called(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """ErrorAnalyzer est appel√© pour les erreurs"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=32,
            expected=42,
            user_id="student_123"
        )

        # V√©rifier que l'analyse a √©t√© faite
        assert result.is_correct is False
        assert result.confidence > 0
        assert result.remediation is not None

    def test_integration_feedback_templates_used(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Templates de feedback sont utilis√©s si disponibles"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=32,  # Erreur de retenue
            expected=42,
            user_id="student_123"
        )

        # L'explication devrait √™tre construite
        assert len(result.explanation) > 0
        assert result.explanation != ""

    def test_integration_remediation_path_used(
        self,
        feedback_engine,
        sample_multiplication_exercise
    ):
        """Chemin de rem√©diation utilis√©"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_multiplication_exercise,
            response=49,
            expected=56,
            user_id="student_123"
        )

        # Remediation devrait pointer vers un chemin sp√©cifique
        if result.remediation:
            assert "exercise_path" in result.remediation
            assert len(result.remediation["exercise_path"]) > 0


# ============================================================================
# TESTS - TransformativeFeedback - Edge Cases
# ============================================================================

class TestTransformativeFeedbackEdgeCases:
    """Tests des cas limites"""

    def test_empty_exercise(self, feedback_engine):
        """Exercice vide"""
        result = feedback_engine.process_exercise_response(
            exercise={},
            response=42,
            expected=42,
            user_id="student_123"
        )

        # Devrait quand m√™me fonctionner
        assert result is not None
        assert result.is_correct is True

    def test_none_response(self, feedback_engine, sample_addition_exercise):
        """R√©ponse None"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=None,
            expected=42,
            user_id="student_123"
        )

        assert result.is_correct is False
        assert result.immediate.startswith("‚ùå")

    def test_empty_string_response(self, feedback_engine, sample_addition_exercise):
        """R√©ponse cha√Æne vide"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response="",
            expected=42,
            user_id="student_123"
        )

        assert result.is_correct is False

    def test_no_user_history(self, feedback_engine, sample_addition_exercise):
        """Sans historique utilisateur"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=42,
            expected=42,
            user_id="student_new",
            user_history=None
        )

        # Devrait fonctionner avec feedback g√©n√©rique
        assert result.is_correct is True
        assert len(result.encouragement) > 0

    def test_malformed_user_history(self, feedback_engine, sample_addition_exercise):
        """Historique utilisateur malform√©"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=42,
            expected=42,
            user_id="student_123",
            user_history={"invalid": "data"}
        )

        # Devrait g√©rer gracieusement
        assert result.is_correct is True
        assert result.next_action in ["Continuer", "Niveau suivant"]

    def test_zero_time_taken(self, feedback_engine, sample_addition_exercise):
        """Temps de r√©ponse = 0"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=42,
            expected=42,
            user_id="student_123",
            time_taken_seconds=0
        )

        assert result.is_correct is True

    def test_negative_time_taken(self, feedback_engine, sample_addition_exercise):
        """Temps de r√©ponse n√©gatif"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=42,
            expected=42,
            user_id="student_123",
            time_taken_seconds=-5
        )

        # Devrait g√©rer gracieusement
        assert result.is_correct is True

    def test_very_large_numbers(self, feedback_engine):
        """Nombres tr√®s grands"""
        result = feedback_engine.process_exercise_response(
            exercise={
                "type": "addition",
                "operation": "999999 + 1",
                "difficulty": "CM2"
            },
            response=1000000,
            expected=1000000,
            user_id="student_123"
        )

        assert result.is_correct is True

    def test_decimal_response(self, feedback_engine):
        """R√©ponse d√©cimale"""
        result = feedback_engine.process_exercise_response(
            exercise={
                "type": "division",
                "operation": "10 √∑ 4",
                "difficulty": "CM1"
            },
            response=2.5,
            expected=2.5,
            user_id="student_123"
        )

        assert result.is_correct is True

    def test_fraction_response(self, feedback_engine):
        """R√©ponse fractionnaire"""
        result = feedback_engine.process_exercise_response(
            exercise={
                "type": "fraction",
                "operation": "1/2 + 1/4",
                "difficulty": "CM2"
            },
            response="3/4",
            expected=0.75,
            user_id="student_123"
        )

        assert result.is_correct is True


# ============================================================================
# TESTS - Alias FeedbackGenerator
# ============================================================================

class TestFeedbackGeneratorAlias:
    """Tests pour l'alias FeedbackGenerator"""

    def test_alias_exists(self):
        """L'alias FeedbackGenerator existe"""
        assert FeedbackGenerator is not None
        assert FeedbackGenerator == TransformativeFeedback

    def test_alias_instantiation(self):
        """Peut instancier via l'alias"""
        generator = FeedbackGenerator()
        assert isinstance(generator, TransformativeFeedback)
        assert hasattr(generator, 'process_exercise_response')


# ============================================================================
# TESTS - Performance et Robustesse
# ============================================================================

class TestPerformanceAndRobustness:
    """Tests de performance et robustesse"""

    def test_multiple_sequential_calls(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Multiples appels s√©quentiels"""
        results = []
        for i in range(10):
            result = feedback_engine.process_exercise_response(
                exercise=sample_addition_exercise,
                response=42 if i % 2 == 0 else 32,
                expected=42,
                user_id=f"student_{i}"
            )
            results.append(result)

        assert len(results) == 10
        # Alterner succ√®s/√©chec
        assert results[0].is_correct is True
        assert results[1].is_correct is False

    def test_randomness_in_messages(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Messages varient (randomness)"""
        immediates = set()
        for _ in range(20):
            result = feedback_engine.process_exercise_response(
                exercise=sample_addition_exercise,
                response=42,
                expected=42,
                user_id="student_123"
            )
            immediates.add(result.immediate)

        # Devrait avoir au moins 2-3 variantes diff√©rentes
        assert len(immediates) >= 2

    def test_different_exercises_different_strategies(
        self,
        feedback_engine,
        sample_addition_exercise,
        sample_multiplication_exercise,
        sample_subtraction_exercise
    ):
        """Exercices diff√©rents ‚Üí strat√©gies diff√©rentes"""
        add_result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=32,
            expected=42,
            user_id="student_123"
        )

        mult_result = feedback_engine.process_exercise_response(
            exercise=sample_multiplication_exercise,
            response=49,
            expected=56,
            user_id="student_123"
        )

        sub_result = feedback_engine.process_exercise_response(
            exercise=sample_subtraction_exercise,
            response=35,
            expected=25,
            user_id="student_123"
        )

        # Les strat√©gies devraient diff√©rer
        strategies = {
            add_result.strategy,
            mult_result.strategy,
            sub_result.strategy
        }
        assert len(strategies) >= 2  # Au moins 2 strat√©gies diff√©rentes

    def test_timestamp_present(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Timestamp est pr√©sent"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=42,
            expected=42,
            user_id="student_123"
        )

        assert result.timestamp != ""
        # Devrait √™tre un ISO timestamp valide
        try:
            datetime.fromisoformat(result.timestamp)
        except:
            pytest.fail("Timestamp invalide")


# ============================================================================
# TESTS - Messages p√©dagogiques
# ============================================================================

class TestPedagogicalMessages:
    """Tests des messages p√©dagogiques"""

    def test_immediate_messages_appropriate_length(self, feedback_engine):
        """Messages imm√©diats ont longueur appropri√©e"""
        # Tester tous les messages pr√©-d√©finis
        for msg in feedback_engine.immediate_success:
            assert len(msg.split()) <= 6  # Max ~5 mots

        for msg in feedback_engine.immediate_close:
            assert len(msg.split()) <= 6

        for msg in feedback_engine.immediate_wrong:
            assert len(msg.split()) <= 6

    def test_explanation_not_too_long(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Explications ne sont pas trop longues (max ~50 mots)"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=32,
            expected=42,
            user_id="student_123"
        )

        word_count = len(result.explanation.split())
        # Flexible mais raisonnable
        assert word_count <= 80

    def test_strategy_not_too_long(
        self,
        feedback_engine,
        sample_multiplication_exercise
    ):
        """Strat√©gies ne sont pas trop longues (max ~50 mots)"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_multiplication_exercise,
            response=49,
            expected=56,
            user_id="student_123"
        )

        if result.strategy:
            word_count = len(result.strategy.split())
            assert word_count <= 80

    def test_encouragement_always_positive(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Encouragement est toujours positif"""
        # Tester avec √©chec
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=32,
            expected=42,
            user_id="student_123"
        )

        # Ne devrait pas contenir de mots n√©gatifs durs
        encouragement_lower = result.encouragement.lower()
        negative_words = ["mauvais", "nul", "√©chec", "rat√©", "faux"]
        for word in negative_words:
            assert word not in encouragement_lower


# ============================================================================
# TESTS - Couverture compl√®te
# ============================================================================

class TestCompleteCoverage:
    """Tests pour maximiser la couverture"""

    def test_build_success_insight(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Test de _build_success_insight"""
        insight = feedback_engine._build_success_insight(
            sample_addition_exercise,
            time_taken=5
        )
        assert len(insight) > 0

    def test_build_success_encouragement_no_history(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Encouragement sans historique"""
        encouragement = feedback_engine._build_success_encouragement(
            user_id="student_123",
            user_history=None,
            exercise=sample_addition_exercise
        )
        assert len(encouragement) > 0

    def test_build_success_encouragement_medium_rate(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Encouragement avec taux moyen"""
        encouragement = feedback_engine._build_success_encouragement(
            user_id="student_123",
            user_history={"success_rate": 0.7},
            exercise=sample_addition_exercise
        )
        assert "progress" in encouragement.lower() or "bien" in encouragement.lower()

    def test_build_error_explanation_no_templates(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Explication sans templates (fallback)"""
        # Cr√©er analyse sans templates
        error_analysis = ErrorAnalysisResult(
            error_type="Calculation",
            misconception="Erreur de calcul",
            severity=2,
            confidence=0.6,
            examples=[],
            prerequisites_gaps=[],
            remediation_strategy="Pratiquer",
            common_ages=["7-9 ans"],
            feedback_templates=[]  # Pas de templates
        )

        explanation = feedback_engine._build_error_explanation(
            error_analysis,
            sample_addition_exercise,
            response=32,
            expected=42
        )

        # Devrait utiliser fallback
        assert "32" in explanation
        assert "42" in explanation

    def test_build_alternative_strategy_unknown_type(
        self,
        feedback_engine
    ):
        """Strat√©gie pour type inconnu"""
        error_analysis = ErrorAnalysisResult(
            error_type="Unknown",
            misconception="Erreur inconnue",
            severity=2,
            confidence=0.5,
            examples=[],
            prerequisites_gaps=[],
            remediation_strategy="Review",
            common_ages=[]
        )

        strategy = feedback_engine._build_alternative_strategy(
            error_analysis,
            {"type": "unknown_type"}
        )

        # Devrait retourner strat√©gie g√©n√©rique
        assert "dessine" in strategy.lower() or "mat√©riel" in strategy.lower()

    def test_determine_next_action_success_no_history(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Action suivante succ√®s sans historique"""
        action = feedback_engine._determine_next_action_success(
            sample_addition_exercise,
            user_history=None
        )
        assert action == "Continuer"

    def test_all_error_severity_levels(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Test toutes les s√©v√©rit√©s d'erreur"""
        # Severity 1
        result1 = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=41,
            expected=42,
            user_id="student_123"
        )

        # Severity √©lev√©e (confondre op√©rations)
        result2 = feedback_engine.process_exercise_response(
            exercise={
                "type": "addition",
                "operation": "7 + 8",
                "difficulty": "CE1"
            },
            response=56,  # 7√ó8
            expected=15,
            user_id="student_123"
        )

        # Les deux devraient avoir des feedbacks diff√©rents
        assert result1.next_action != result2.next_action or \
               result1.remediation["practice_count"] != result2.remediation["practice_count"]


# ============================================================================
# TESTS - Validation finale
# ============================================================================

class TestFinalValidation:
    """Tests de validation finale"""

    def test_feedback_result_json_serializable(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """R√©sultat s√©rialisable en JSON"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=42,
            expected=42,
            user_id="student_123"
        )

        result_dict = result.to_dict()

        # Devrait pouvoir s√©rialiser en JSON
        try:
            json.dumps(result_dict)
        except:
            pytest.fail("R√©sultat non s√©rialisable en JSON")

    def test_all_six_layers_present_on_failure(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Les 6 couches pr√©sentes pour √©chec"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=32,
            expected=42,
            user_id="student_123"
        )

        # V√©rifier les 6 couches
        assert result.immediate != ""  # Layer 1
        assert result.explanation != ""  # Layer 2
        assert result.strategy is not None  # Layer 3
        assert result.remediation is not None  # Layer 4
        assert result.encouragement != ""  # Layer 5
        assert result.next_action != ""  # Layer 6

    def test_all_six_layers_present_on_success(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Les 6 couches pr√©sentes pour succ√®s"""
        result = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=42,
            expected=42,
            user_id="student_123"
        )

        # V√©rifier les couches cl√©s
        assert result.immediate != ""  # Layer 1
        assert result.explanation != ""  # Layer 2
        # strategy peut √™tre None ou pr√©sent pour succ√®s
        # remediation est None pour succ√®s
        assert result.remediation is None  # Layer 4: pas de rem√©diation si succ√®s
        assert result.encouragement != ""  # Layer 5
        assert result.next_action != ""  # Layer 6

    def test_confidence_in_valid_range(
        self,
        feedback_engine,
        sample_addition_exercise
    ):
        """Confiance dans intervalle valide [0, 1]"""
        # Test succ√®s
        result_success = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=42,
            expected=42,
            user_id="student_123"
        )
        assert 0.0 <= result_success.confidence <= 1.0

        # Test √©chec
        result_failure = feedback_engine.process_exercise_response(
            exercise=sample_addition_exercise,
            response=32,
            expected=42,
            user_id="student_123"
        )
        assert 0.0 <= result_failure.confidence <= 1.0

    def test_system_handles_all_operations(self, feedback_engine):
        """Syst√®me g√®re toutes les op√©rations de base"""
        operations = [
            {"type": "addition", "response": 10, "expected": 10},
            {"type": "subtraction", "response": 5, "expected": 5},
            {"type": "multiplication", "response": 24, "expected": 24},
            {"type": "division", "response": 4, "expected": 4}
        ]

        for op in operations:
            result = feedback_engine.process_exercise_response(
                exercise={
                    "type": op["type"],
                    "operation": "test",
                    "difficulty": "CE2"
                },
                response=op["response"],
                expected=op["expected"],
                user_id="student_123"
            )
            assert result is not None
            assert result.is_correct is True


# ============================================================================
# STATISTIQUES DE COUVERTURE
# ============================================================================

def test_coverage_summary():
    """R√©sum√© de couverture attendue"""
    # Ce test sert juste √† documenter
    # La couverture r√©elle sera mesur√©e par pytest-cov

    covered_components = [
        "TransformativeFeedbackResult",
        "RemediationRecommender",
        "TransformativeFeedback",
        "process_exercise_response",
        "_check_answer",
        "_parse_number",
        "_generate_success_feedback",
        "_generate_failure_feedback",
        "_build_success_explanation",
        "_build_success_insight",
        "_build_success_encouragement",
        "_build_error_explanation",
        "_build_alternative_strategy",
        "_build_failure_encouragement",
        "_determine_next_action_success",
        "_determine_next_action_failure",
        "recommend_exercise",
        "_adjust_difficulty",
        "_get_exercise_type"
    ]

    assert len(covered_components) >= 15


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--cov=core.pedagogy.feedback_engine", "--cov-report=term-missing"])
